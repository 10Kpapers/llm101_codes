{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_papers(json_file_path):\n",
    "    papers = []\n",
    "    paper_count = 0\n",
    "    with open(json_file_path, encoding=\"utf-8\") as fi:\n",
    "        for line in tqdm(fi):\n",
    "            paper_count += 1\n",
    "            papers.append(json.loads(line))\n",
    "    print(f\"This file contains {paper_count} papers\")\n",
    "    return papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]2601564it [01:20, 32414.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This file contains 2601564 papers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "papers = count_papers(\"./arxiv-metadata-oai-snapshot.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0704.0001',\n",
       " 'submitter': 'Pavel Nadolsky',\n",
       " 'authors': \"C. Bal\\\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\",\n",
       " 'title': 'Calculation of prompt diphoton production cross sections at Tevatron and\\n  LHC energies',\n",
       " 'comments': '37 pages, 15 figures; published version',\n",
       " 'journal-ref': 'Phys.Rev.D76:013009,2007',\n",
       " 'doi': '10.1103/PhysRevD.76.013009',\n",
       " 'report-no': 'ANL-HEP-PR-07-12',\n",
       " 'categories': 'hep-ph',\n",
       " 'license': None,\n",
       " 'abstract': '  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n',\n",
       " 'versions': [{'version': 'v1', 'created': 'Mon, 2 Apr 2007 19:18:42 GMT'},\n",
       "  {'version': 'v2', 'created': 'Tue, 24 Jul 2007 20:10:27 GMT'}],\n",
       " 'update_date': '2008-11-26',\n",
       " 'authors_parsed': [['Balázs', 'C.', ''],\n",
       "  ['Berger', 'E. L.', ''],\n",
       "  ['Nadolsky', 'P. M.', ''],\n",
       "  ['Yuan', 'C. -P.', '']]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categories含义：https://arxiv.org/category_taxonomy\n",
    "\n",
    "'cs.AI': 'Artificial Intelligence',\n",
    "\n",
    "'cs.CL': 'Computation and Language',\n",
    "\n",
    "'cs.IR': 'Information Retrieval',\n",
    "\n",
    "'cs.LG': 'Machine Learning',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62081"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 只保留[cs.AI, cs.CL, cs.IR, cs.LG]领域的论文  TODO 你可以扩展其他领域的论文\n",
    "cs_papers = [paper for paper in papers if paper[\"categories\"] in set(['cs.AI', 'cs.CL', 'cs.IR', 'cs.LG'])]\n",
    "len(cs_papers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0704.1274',\n",
       " 'title': 'Parametric Learning and Monte Carlo Optimization',\n",
       " 'abstract': \"  This paper uncovers and explores the close relationship between Monte Carlo\\nOptimization of a parametrized integral (MCO), Parametric machine-Learning\\n(PL), and `blackbox' or `oracle'-based optimization (BO). We make four\\ncontributions. First, we prove that MCO is mathematically identical to a broad\\nclass of PL problems. This identity potentially provides a new application\\ndomain for all broadly applicable PL techniques: MCO. Second, we introduce\\nimmediate sampling, a new version of the Probability Collectives (PC) algorithm\\nfor blackbox optimization. Immediate sampling transforms the original BO\\nproblem into an MCO problem. Accordingly, by combining these first two\\ncontributions, we can apply all PL techniques to BO. In our third contribution\\nwe validate this way of improving BO by demonstrating that cross-validation and\\nbagging improve immediate sampling. Finally, conventional MC and MCO procedures\\nignore the relationship between the sample point locations and the associated\\nvalues of the integrand; only the values of the integrand at those locations\\nare considered. We demonstrate that one can exploit the sample location\\ninformation using PL techniques, for example by forming a fit of the sample\\nlocations to the associated values of the integrand. This provides an\\nadditional way to apply PL techniques to improve MCO.\\n\",\n",
       " 'categories': 'cs.LG'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 只保留id, title, abstract, categories\n",
    "cs_papers = [{\n",
    "    \"id\": paper[\"id\"],\n",
    "    \"title\": paper[\"title\"],\n",
    "    \"abstract\": paper[\"abstract\"],\n",
    "    \"categories\": paper[\"categories\"]\n",
    "} for paper in cs_papers if paper[\"abstract\"].strip()]\n",
    "len(cs_papers)\n",
    "cs_papers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62081"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cs_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('arxiv_cs-metadata.json', 'w') as f:\n",
    "    for item in cs_papers:\n",
    "        f.write(json.dumps(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
