GPT-1: Improving Language Understanding by Generative Pre-Training [finetune-transformer-lm](https://github.com/openai/finetune-transformer-lm)

GPT-2: Language Models are Unsupervised Multitask Learners [gpt-2](https://github.com/openai/gpt-2)

LLM training in simple [llm.c](https://github.com/karpathy/llm.c)

NanoGPT (124M) in 5 minutes [modded-nanogpt](https://github.com/KellerJordan/modded-nanogpt)